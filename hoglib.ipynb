{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hoglib.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcokSEx3Cjll"
      },
      "source": [
        "# A rudimentary implementation of the Histograms of Oriented Gradients image classification algorithm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtqWJ5aWCjln"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import hoglib as hog\n",
        "from importlib import reload\n",
        "import time\n",
        "import sys\n",
        "import pickle \n",
        "import os\n",
        "import progressbar as pb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-0ZlSKjCjlq"
      },
      "source": [
        "## Histogram generators\n",
        "The following methods take raw images (with normalized dimensions) as input, and produce histograms suitable as descriptors in a learned classification algorithm, such as SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt-o58X-Cjlq"
      },
      "source": [
        "def _convolve(image, conv_matrix):\n",
        "    \"\"\"\n",
        "    DEPRECATED: use _detect_edge_vert and _detect_edge_hor insetead!\n",
        "    Performs a convolution on a given image using a given \n",
        "    convolutional matrix. Edge overflow is considered to be zeros (black).\n",
        "    \"\"\"\n",
        "    conv_matrix = conv_matrix/np.linalg.norm(conv_matrix)\n",
        "    v_reach = int(conv_matrix.shape[0]/2)\n",
        "    h_reach = int(conv_matrix.shape[1]/2)\n",
        "    expanded_image = np.zeros(np.array(conv_matrix.shape)-1+image.shape)\n",
        "    expanded_image[v_reach:-v_reach, h_reach:-v_reach]=image\n",
        "    result = np.zeros(image.shape)\n",
        "    for (i, j), _ in np.ndenumerate(image):\n",
        "        result[i, j] = (conv_matrix*expanded_image[i:i+2*v_reach+1, j:j+2*h_reach+1]).sum()\n",
        "    return result\n",
        "\n",
        "def _detect_edge_vert(image):\n",
        "    \"\"\"\n",
        "    Performs a convolution between the argument image and the vector [-1, 0, 1],\n",
        "    thereby detecting vertical edges. The output is a convolution with the same\n",
        "    dimensions as the input image. Edge overflow is treated as being 0.\n",
        "    \"\"\"\n",
        "    #TODO: Optimize by using numpy.convolve\n",
        "    output = np.zeros(image.shape)\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(1,image.shape[1]-1):\n",
        "            output[i,j] = image[i,j+1] - image[i,j-1]\n",
        "        output[i,0] = image[i,1]\n",
        "        output[i, -1] = -image[i, -2]\n",
        "    return output\n",
        "\n",
        "def _detect_edge_hor(image):\n",
        "    \"\"\"\n",
        "    Performs a convolution between the argument image and the vector [-1; 0; 1],\n",
        "    thereby detecting horizontal edges. The output is a convolution with the same\n",
        "    dimensions as the input image. Edge overflow is treated as being 0.\n",
        "    \"\"\"\n",
        "    #TODO: Optimize by using numpy.convolve\n",
        "    output = np.zeros(image.shape)\n",
        "    for j in range(image.shape[1]):\n",
        "        for i in range(1,image.shape[0]-1):\n",
        "            output[i,j] = image[i+1,j] - image[i-1,j]\n",
        "        output[0, j] = -image[1,j]\n",
        "        output[-1, j] = image[-2, j]\n",
        "    return output\n",
        "\n",
        "def _vec_to_deg_unsigned(vec):\n",
        "    #TODO: Optimization, this is way slower than it should be!\n",
        "    \"\"\"\n",
        "    Calculates the unsigned angle (0-180) of a given vector\n",
        "    in relation to the positive x-axis.\n",
        "    \"\"\"\n",
        "    if np.linalg.norm(vec) < 1e-10: \n",
        "        return 0\n",
        "    else:\n",
        "        deg = np.arccos(vec[0]/np.sqrt((vec[0]**2) + (vec[1]**2)))\n",
        "        return deg*180/np.pi\n",
        "    \n",
        "def _rectify_angle(angle):\n",
        "    \"\"\"\n",
        "    Converts an unsigned angle from the [-90, 90] format to the [0 180] format.\n",
        "    \"\"\"\n",
        "    return angle if angle>0 else angle+180\n",
        "\n",
        "def get_gradient_matrix(image):\n",
        "    \"\"\"\n",
        "    Calculates the gradient matrix M of a given m-by-n input image.\n",
        "    On exit, M is an m-by-n-by-2 tensor such that:\n",
        "      M[:,:,0] represents the magnitude of the gradient vector\n",
        "        for each pixel in the input image\n",
        "      M[:,:,1] represents the angle of each vector\n",
        "    \"\"\"\n",
        "    # Calculate gradients\n",
        "    if len(image.shape) == 2:\n",
        "        new_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
        "        new_image[:,:,0] = image\n",
        "        image = new_image\n",
        "        \n",
        "    gr_h_r = _detect_edge_hor(image[:,:,0])\n",
        "    gr_h_g = _detect_edge_hor(image[:,:,1])\n",
        "    gr_h_b = _detect_edge_hor(image[:,:,2])\n",
        "    gr_v_r = _detect_edge_vert(image[:,:,0])\n",
        "    gr_v_g = _detect_edge_vert(image[:,:,1])\n",
        "    gr_v_b = _detect_edge_vert(image[:,:,2])\n",
        "    gr_h = np.maximum(np.maximum(gr_h_r, gr_h_g), gr_h_b)\n",
        "    gr_v = np.maximum(np.maximum(gr_v_r, gr_v_g), gr_v_b)\n",
        "    output = np.zeros([gr_v.shape[0], gr_v.shape[1], 2])\n",
        "    # Save gradient magnitude\n",
        "    output[:,:,0] = np.linalg.norm([gr_h,gr_v], axis=0)\n",
        "    \n",
        "    output[:,:,1] = np.angle(gr_v+gr_h*1j, deg = True)\n",
        "    rectify = np.vectorize(_rectify_angle)\n",
        "    output[:,:,1] = rectify(output[:,:,1])\n",
        "\n",
        "    return output   #M\n",
        "\n",
        "def _get_cos_bins(num_bins = 9):\n",
        "#     TODO: Distribute vector across adjacent bins according to angle\n",
        "    \"\"\"\n",
        "    DEPRECATED\n",
        "    Returns a list of cosine values corresponding to an equidistant\n",
        "    distribution of vector angles into num_bins categories.\n",
        "    \"\"\"\n",
        "    cos_vals = np.cos(np.pi*np.linspace(0,num_bins,num_bins+1)/num_bins)\n",
        "    return [np.sign(cos_val)*cos_val**2 for cos_val in cos_vals]\n",
        "\n",
        "def _vec_to_bin(x, y, num_bins = 9, \n",
        "               cosine_bins_squared = None):\n",
        "    \"\"\"\n",
        "    DEPRECATED\n",
        "    Assigns a vector [x, y] to one of num_bins categories depending on its angle.\n",
        "    Strongly advise to pre-calculate cosine_bins_squared if this function will be used\n",
        "    repeatedly.\n",
        "    \"\"\"\n",
        "    if (abs(x) < 0.1) and (abs(y) < 0.1): return 0 # discarding small gradients - yes or no?\n",
        "    if cosine_bins_squared is None: cbs = _get_cos_bins(num_bins)\n",
        "    else: cbs = cosine_bins_squared\n",
        "    if y < 0: x, y = -x, -y\n",
        "    cos_squared = np.sign(x)*(x**2)/(x**2+y**2)\n",
        "    for i in range(num_bins): \n",
        "        if cbs[i] >= cos_squared > cbs[i+1]: return i\n",
        "    if cos_squared == -1: return 8\n",
        "    raise RuntimeError(\"Vector \" + str([x,y]) + \" could not be placed into any bin!\")\n",
        "    return 0    \n",
        "\n",
        "def _get_bin(angle, num_bins): \n",
        "    \"\"\"\n",
        "    DEPRECATED\n",
        "    Sorts an angle into one of a number of distinct categories, \n",
        "    or 'bins'. For example, 3 bins will each represent 60 degrees,\n",
        "    so the angles 45, 65 and 175 degrees belong into bins\n",
        "    0, 1 and 2 respectively\n",
        "    \"\"\"\n",
        "    return int(round((angle/180)*(num_bins-1)))\n",
        "\n",
        "\n",
        "def get_histogram(gradient_matrix, num_bins=9):\n",
        "    \"\"\"\n",
        "    Takes a matrix of gradient vectors (see get_gradient_matrix()), \n",
        "    assigns them all into different bins and finally builds a histogram\n",
        "    the x-axis of the histogram represents the possible bins\n",
        "    (0, 1, 2,..., num_bins). Each gradient vector adds its magnitude\n",
        "    to the appropriate bin.\n",
        "    \"\"\"    \n",
        "    gm=gradient_matrix\n",
        "    histogram = np.zeros(num_bins)\n",
        "    for (i,j), _ in np.ndenumerate(gm[:,:,0]):\n",
        "        histogram[int(gm[i,j,1])] += gm[i,j,0]\n",
        "    return histogram\n",
        "\n",
        "\n",
        "def crop_image(image, cell_height=8, cell_width=8):\n",
        "    \n",
        "    \"\"\"\n",
        "    DEPRECATED: Use hoglib.resize() instead\n",
        "    Crops the bottom and right hand edges of an image so its\n",
        "    height and width are multiples of cell_height and cell_width \n",
        "    respectively\n",
        "    \"\"\"\n",
        "    if image.shape[0]%cell_height:\n",
        "        image = image[:-(image.shape[0]%cell_height),:]\n",
        "    if image.shape[1]%cell_width:\n",
        "        image[:,:-(image.shape[1]%cell_width)]\n",
        "    return image\n",
        "\n",
        "def _grad_to_hist(mag, angle, num_bins=9):\n",
        "    hist = np.zeros(num_bins)\n",
        "    bin_width = 180/num_bins\n",
        "    bin_centers = np.array(range(1,num_bins+1))*bin_width-bin_width/2\n",
        "    \n",
        "    #determine index of left-hand and right-hand bins\n",
        "    if angle <= bin_centers[0]:\n",
        "        idx_left = num_bins-1\n",
        "        idx_right = 0\n",
        "        factor = angle/bin_width + 0.5\n",
        "    elif bin_centers[0] < angle < bin_centers[-1]:\n",
        "        idx_left = bin_centers[bin_centers<angle].size-1\n",
        "        idx_right = idx_left+1\n",
        "        factor = (angle-bin_centers[idx_left])/bin_width\n",
        "    else:\n",
        "        idx_left = num_bins-1\n",
        "        idx_right = 0\n",
        "        factor = (angle-bin_centers[-1])/bin_width\n",
        "    \n",
        "    if not 0<factor<=1:\n",
        "        raise RuntimeError(('Error determining appropriate bin for gradient with'\n",
        "                            'angle {0}; magnitude {1} (adjacent bins'\n",
        "                            '{2} and {3}, total bins {4}').format(\n",
        "                                angle, mag, idx_left, idx_right, num_bins))\n",
        "    \n",
        "    #generate individual histogram\n",
        "    hist[idx_left] = (1-factor)*mag\n",
        "    hist[idx_right] = factor*mag\n",
        "    return hist\n",
        "\n",
        "def get_cell_histograms_8x8(grad_mat, num_cells_height, num_cells_width, num_bins=9):\n",
        "    \"\"\"\n",
        "    Partitiones the image into a 32x32 grid of 8x8 pixel cells, then produces a \n",
        "    histogram for each cell (see get_histogram()).\n",
        "    The output is a 32-by-32-by-num_bins tensor such that the slice [i,j,:] represents\n",
        "    the histogram for the (i,j)-th grid tile of the source image.\n",
        "    \"\"\"\n",
        "    #TODO: clean some of this hard code\n",
        "    cell_histograms = np.zeros((num_cells_height, num_cells_width, num_bins))\n",
        "    for i in range(num_cells_height):\n",
        "        for j in range(num_cells_width):\n",
        "            cell_histogram_current = np.zeros(num_bins)\n",
        "            for i2 in range(8):\n",
        "                for j2 in range(8):\n",
        "                    cell_histogram_current = cell_histogram_current \\\n",
        "                                            + _grad_to_hist(\n",
        "                                                grad_mat[i*8+i2, j*8+j2,0],\n",
        "                                                grad_mat[i*8+i2, j*8+j2,1],\n",
        "                                                num_bins)\n",
        "            cell_histograms[i,j,:] = cell_histogram_current\n",
        "    return cell_histograms\n",
        "\n",
        "def L2_norm(v, eps):\n",
        "    \"\"\"Return the L2-norm with regularization\"\"\"\n",
        "    return np.sqrt(v@v+eps)\n",
        "\n",
        "def get_block_histograms_8x8(cell_histograms, num_bins=9):\n",
        "    \"\"\"\n",
        "    Just check the paper idk\n",
        "    \"\"\"\n",
        "    ch = cell_histograms\n",
        "    height = ch.shape[0]-1\n",
        "    width = ch.shape[1]-1\n",
        "    cells = np.zeros((height, width, num_bins*4))\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            current = np.zeros(num_bins*4)\n",
        "            current[0*num_bins:1*num_bins] = ch[i,j,:]\n",
        "            current[1*num_bins:2*num_bins] = ch[i+1,j,:]\n",
        "            current[2*num_bins:3*num_bins] = ch[i,j+1,:]\n",
        "            current[3*num_bins:4*num_bins] = ch[i+1,j+1,:]\n",
        "            #normalize using L2-norm with regularization \n",
        "            cells[i,j] = current/L2_norm(current, 1e-5)\n",
        "    return np.ravel(cells)\n",
        "\n",
        "def show_histogram(image, cell_histograms, i=0, j=0, cell_height=8, cell_width=8):\n",
        "    \"\"\"\n",
        "    Displays the relevant image, a single cell within it \n",
        "    (indexed by i and j), and finally the histogram relevant \n",
        "    to that cell.\n",
        "    \"\"\"\n",
        "    h = cell_height; w = cell_width\n",
        "\n",
        "    fig, (g1, g2, g3) = plt.subplots(3,1)\n",
        "    g1.imshow(image, cmap='gray')\n",
        "    g1.plot(    [j*w, (j+1)*w, (j+1)*w, j*w, j*w], \n",
        "                [i*h, i*h, (i+1)*h, (i+1)*h, i*h], 'r-')\n",
        "    g2.imshow(image[i*h:(i+1)*h, j*w:(j+1)*w], cmap='gray')\n",
        "    g2.plot(    [0, w-1, w-1, 0, 0], \n",
        "                [0, 0, h-1, h-1, 0], 'r--')\n",
        "    g3.bar(range(0,9), cell_histograms[i,j,:], align='center', width=0.9)\n",
        "    \n",
        "def seconds_to_timestamp(elapsed):\n",
        "    \"\"\"\n",
        "    Convert a time period (expressed by a number of seconds elapsed) to a timestamp and returns\n",
        "    the number of hours, minutes and seconds elapsed.\n",
        "    \n",
        "    Example: \n",
        "        seconds_to_timestamp(3824) = [1, 3, 44]\n",
        "    \"\"\"\n",
        "    hours = elapsed//3600\n",
        "    minutes = (elapsed-3600*hours)//60\n",
        "    seconds = (elapsed - 3600*hours - 60*minutes)\n",
        "    return [hours, minutes, seconds]\n",
        "\n",
        "#DEPRECATED\n",
        "def get_descriptors(train_set):\n",
        "    \"\"\"\n",
        "    DEPRECATED\n",
        "    Generates HOG descriptors for all images in a given set. Input should be an array of grayscale, 256x256\n",
        "    image matrices. Output will be an array of 31x31 numpy arrays, such that each element in each of the numpy\n",
        "    arrays represents the histogram for one block of the corresponding image.\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    total = len(train_set)\n",
        "    train_descriptors = [] \n",
        "    start = time.time()\n",
        "    elapsed_previous = 0\n",
        "    for image in train_set:\n",
        "        current_grad = get_gradient_matrix(image)\n",
        "        train_descriptors.append(get_block_histograms_8x8(get_cell_histograms_8x8(current_grad)))\n",
        "        elapsed = time.time()-start\n",
        "        frametime = elapsed-elapsed_previous\n",
        "        elapsed_previous = elapsed\n",
        "        elapsed_hours, elapsed_minutes, elapsed_seconds = seconds_to_timestamp(elapsed)\n",
        "        remaining_hours, remaining_minutes, remaining_seconds = seconds_to_timestamp(elapsed*(total/max(1,i)-1))\n",
        "        remaining = elapsed\n",
        "        i = i+1\n",
        "        progress = 100*i/total\n",
        "        progress_bar= int(progress/5)\n",
        "        sys.stdout.write('\\r')\n",
        "        sys.stdout.write(\"[%-20s] %d%% (%d/%d); elapsed: %dh, %dm, %.2fs; remaining: %dh, %dm, %.2fs; frametime: %.2f\" % (\n",
        "            '='*progress_bar, progress, i, total, \n",
        "            elapsed_hours, elapsed_minutes, elapsed_seconds,\n",
        "            remaining_hours, remaining_minutes, remaining_seconds, frametime*1000))\n",
        "        sys.stdout.flush()\n",
        "    return train_descriptors\n",
        "\n",
        "def get_descriptor(img):\n",
        "    \"\"\"Obtain the feature vector for a single image matrix\"\"\"\n",
        "    num_cells_height = int(np.floor(img.shape[0]/8))\n",
        "    num_cells_width = int(np.floor(img.shape[1]/8))\n",
        "    return get_block_histograms_8x8(\n",
        "                get_cell_histograms_8x8(\n",
        "                    get_gradient_matrix(\n",
        "                        img), num_cells_height, num_cells_width))\n",
        "\n",
        "def _extract_descriptors(path, width, height):\n",
        "    \"\"\"\n",
        "    Generates HOG descriptors for all images in a given set. Input should be the path to an image database, \n",
        "    such that the structure is split into a training and testing folder, and each of those is further split into\n",
        "    a 'positive' and a 'negative' folder. \n",
        "    \n",
        "    Output is four arrays of numpy.array items such that each item is a histogram representation of one of the images\n",
        "    in the database. \n",
        "    \"\"\"\n",
        "    filenames = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
        "    print('\\nCommencing descriptor extraction for '+path)\n",
        "    matrices = [resize(plt.imread(path+'/'+filename), height, width) for filename in pb.progressbar(filenames)]\n",
        "    print('\\nExtracted ' + str(len(matrices)) + ' image matrices')\n",
        "    gradient_tensors = [get_gradient_matrix(image_matrix) for image_matrix in pb.progressbar(matrices)]\n",
        "    print('\\nFinished building gradients')\n",
        "    matrices = None\n",
        "    num_cells_height = int(np.floor(height/8))\n",
        "    num_cells_width = int(np.floor(width/8))\n",
        "    descriptors = [get_block_histograms_8x8(get_cell_histograms_8x8(gradient, num_cells_height, num_cells_width)) \n",
        "                   for gradient in pb.progressbar(gradient_tensors)]\n",
        "    print('\\nDescriptors generated for '+path)\n",
        "    gradient_tensors = None\n",
        "    return descriptors\n",
        "\n",
        "def prepare_data(path, width, height):\n",
        "    if path[-1] != '/':\n",
        "        path = path+'/'\n",
        "    train_desc_pos = _extract_descriptors(path+'train/positive', width, height)\n",
        "    train_desc_neg = _extract_descriptors(path+'train/negative', width, height)\n",
        "    test_desc_pos = _extract_descriptors(path+'test/positive', width, height)\n",
        "    test_desc_neg = _extract_descriptors(path+'test/negative', width, height)\n",
        "    \n",
        "    train_set = np.array(train_desc_pos + train_desc_neg)\n",
        "    train_key = np.append(np.ones(len(train_desc_pos)), np.zeros(len(train_desc_neg)))\n",
        "    test_set = np.array(test_desc_pos + test_desc_neg)\n",
        "    test_key = np.append(np.ones(len(test_desc_pos)), np.zeros(len(test_desc_neg)))\n",
        "    \n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'train_set.p', 'wb') as f:\n",
        "        pickle.dump(train_set, f)\n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'train_key.p', 'wb') as f:\n",
        "        pickle.dump(train_key, f)\n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'test_set.p', 'wb') as f:\n",
        "        pickle.dump(test_set, f)\n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'test_key.p', 'wb') as f:\n",
        "        pickle.dump(test_key, f)\n",
        "    \n",
        "    return (train_set, train_key), (test_set, test_key)  \n",
        "\n",
        "def retrieve_descriptors(path, width, height):\n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'train_set.p', 'rb') as f:\n",
        "        trs=pickle.load(f)\n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'train_key.p', 'rb') as f:\n",
        "        trk=pickle.load(f)\n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'test_set.p', 'rb') as f:\n",
        "        tes=pickle.load(f)\n",
        "    with open(path+str(height)+'x'+str(width)+'_'+'test_key.p', 'rb') as f:\n",
        "        tek=pickle.load(f)\n",
        "    return (trs,trk), (tes,tek)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfudypoWCjls"
      },
      "source": [
        "## Visual Genome driver tools\n",
        "The following methods are used for operating the [Visual Genome](https://visualgenome.org/) dataset after downloading it locally - specifically they locate images of cars in the dataset, then extract sub-images containing only the cars. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QrREt0NCjlt"
      },
      "source": [
        "def load_metadata(path = 'Data/', fname = 'objects.json'):\n",
        "    \"\"\"\n",
        "    Retrieves the Visual Genome database metadata - use before using any further functions!\n",
        "    \"\"\"\n",
        "    with open(path+fname, 'r') as f:\n",
        "        return json.load(f)\n",
        "    #TODO: except IOException, possibly automatically download the metadata\n",
        "\n",
        "def has_car(json_obj = None):\n",
        "    \"\"\"\n",
        "    json_obj should be an element of the json list retrieved by load_metadata()\n",
        "    Returns True if the given image containes a 'car' object\n",
        "    \"\"\"\n",
        "    if json_obj is None:\n",
        "        json_obj = load_metadata();\n",
        "    obj_list = [name for names in [item['names'] for item in json_obj['objects']] for name in names]\n",
        "    return ('car' in obj_list)\n",
        "\n",
        "def get_car_box(json_obj):\n",
        "    \"\"\"\n",
        "    Retrieves a list of all car box coordinates for a given object. Return type is a list even\n",
        "    if there is only a single box to return.\n",
        "    \n",
        "    Parameters:\n",
        "    \n",
        "    json_obj: a jason object as found in the Visual Genome database metadata, containing at least one object\n",
        "        marked 'car'. json_object is an element of the list returned by load_metadata()\n",
        "        \n",
        "    Output:\n",
        "    \n",
        "    Output is a list of dictionaries with 5 keys: id, x, y, h, and w. Each dictionary represents a different car\n",
        "    bounding box in the image associated with the argument.\n",
        "        id: the unique identifier associated with each image in the database. Also found in the names of \n",
        "            each image file\n",
        "        x, y: the row- and column- coordinates for a car bounding box. x is the number of rows from the top,\n",
        "            and y is the number of columns from the left.\n",
        "        h, w: the height and width of the car bounding box. \n",
        "    \"\"\"\n",
        "    car_id = -1\n",
        "    car_list = [obj for obj in json_obj['objects'] if 'car' in obj['names']]\n",
        "    output = []\n",
        "    for obj in car_list:\n",
        "        output.append(\n",
        "                {\n",
        "                'id' : json_obj['image_id'],\n",
        "                'x' : obj['x'],\n",
        "                'y' : obj['y'],\n",
        "                'w' : obj['w'],\n",
        "                'h' : obj['h']\n",
        "                }\n",
        "        )\n",
        "    # Check if output is empty\n",
        "    if not output:\n",
        "        raise RuntimeError(\"No cars found in argument - json_obj should contain at least one car object (car box)\")\n",
        "    return output        \n",
        "\n",
        "def extract_car_section(coordinates):\n",
        "    \"\"\"\n",
        "    Retrieves a sub-section of the image matrix starting at column y, row x \n",
        "    and extending h rows down and w rows to the right\n",
        "    \n",
        "    Parameters:\n",
        "        coordinates: coordinates for the car bounding box (id, x, y, h, w). See get_car_box() for more details.\n",
        "    \n",
        "    Output:\n",
        "        returns a subsection of the parent image containing only the car bounding box (format readable by \n",
        "        matplotlib.pyplot.imshow)\n",
        "    \"\"\"\n",
        "    id = coordinates['id']\n",
        "    c = coordinates\n",
        "    x, y, w, h = c['x'], c['y'], c['w'], c['h'] \n",
        "    im = plt.imread('Data/VG_100K/' + str(id) + '.jpg')\n",
        "    return im[y:y+h, x:x+w]\n",
        "\n",
        "def get_car_boxes(obj_list = None):\n",
        "    \"\"\"Retrieves a list of box-coordinates(id, x, y, height, width) for all car items in a list of objects.\"\"\"\n",
        "    if obj_list is None: \n",
        "        print(\"No object list provided - loading database metadata automatically. This may take a few seconds.\\n\")\n",
        "        obj_list = load_metadata()\n",
        "    output = []\n",
        "    for item in [image for image in obj_list if has_car(image)]: output = output + get_car_box(item)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pHzbZdkCjlv"
      },
      "source": [
        "## General-purpose image processing\n",
        "The following methods are used for slightly pre-processing the image data before feeding it into the HOG exctractor. Namely, they determine whether an image has suitable dimensions, then normalize the image by converting to grayscale, then resizing to a pre-determined size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JCGTOniCjlv"
      },
      "source": [
        "def imread_gs(fname):\n",
        "    img = plt.imread(fname)\n",
        "    img = np.sum(img, axis = 2)/3\n",
        "    max_val = np.max(img)\n",
        "    return img/max_val\n",
        "    \n",
        "def show(img):\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "\n",
        "def _get_distorted_unity(height, width, fill=True): \n",
        "    \"\"\"\n",
        "    Generates a 'pseudo-diagonal' identity matrix, used for transforming dimensions of other matrices.\n",
        "\n",
        "    Parameters:\n",
        "    \n",
        "    height, width : dimensions of the output matrix\n",
        "    fill: \n",
        "        If True, a standard identity matrix is expanded by adding rows or columns containing ones, then normalizing\n",
        "        each row or column. For example:\n",
        "\n",
        "            [1 0 0]\n",
        "            [1 0 0]\n",
        "            [0 1 0]\n",
        "            [0 1 0]\n",
        "            [0 0 1]\n",
        "            [0 0 1]\n",
        "\n",
        "        If False, a standard identity matrix is expanded by adding empty rows or columns. For example:\n",
        "            [1 0 0]\n",
        "            [0 0 0]\n",
        "            [0 1 0]\n",
        "            [0 0 0]\n",
        "            [0 0 1]\n",
        "            [0 0 0]\n",
        "    \"\"\"\n",
        "    M = max(height, width)\n",
        "    m = min(height, width)\n",
        "    if not fill: M, m = m, M\n",
        "    u = np.zeros((M, m))\n",
        "    k = m/M\n",
        "    for i in range(M):\n",
        "        u[i, int(i*k)] = 1\n",
        "    if not fill: u = np.transpose(u)\n",
        "    if height < width: u = np.transpose(u)\n",
        "    return u\n",
        "\n",
        "\n",
        "def transform_height(image, height):\n",
        "    tr_mat = _get_distorted_unity(height, image.shape[0], height > image.shape[0])\n",
        "    return tr_mat@image\n",
        "\n",
        "\n",
        "def transform_width(image, width):\n",
        "    tr_mat = _get_distorted_unity(image.shape[1], width, width > image.shape[1])\n",
        "    return image@tr_mat\n",
        "\n",
        "def suitable_dims(coordinates, min_h = 128, min_w = 128, min_stretch = 0.5, max_stretch = 2):\n",
        "    \"\"\"\n",
        "    Determines wether a car image, specified by the coordinates variable, has dimensions suitable for training. \n",
        "    Images that are too small, or have an extreme ratio between their height and width, are considered unsuitable and the function returns false.\n",
        "    \n",
        "    Parameters:\n",
        "    \n",
        "    coordinates: see get_car_box()\n",
        "    min_h = minimum suitable height (if none, set as 0)\n",
        "    min_w = minimum suitable width (if none, set as 0)\n",
        "    min_stretch = minimum suitable value for the ratio between height and width\n",
        "    max_stretch = maximum suitable value for the ratio between height and width\n",
        "    \"\"\"\n",
        "    c_h = coordinates['h']\n",
        "    c_w = coordinates['w']\n",
        "    if (min_h > 0) and (c_h < min_h): return False\n",
        "    if (min_w>0) and (c_w < min_w): return False\n",
        "    if (min_stretch > 0) and (c_h/c_w < min_stretch): return False\n",
        "    if (max_stretch > 0) and (c_h/c_w > max_stretch): return False\n",
        "    return True\n",
        "\n",
        "def imread(fpath):\n",
        "    \"\"\"\n",
        "    Read an image using matplotlib.pyplot.imread, then normalize it to have 3 color channels.\n",
        "    \"\"\"\n",
        "    img = plt.imread(fpath)\n",
        "    if len(img.shape) == 2:\n",
        "        img_new = np.zeros((img.shape[0], img.shape[1], 3))\n",
        "        img_new[:,:,0] = img\n",
        "        return img_new\n",
        "    return img[:,:,:3]\n",
        "        \n",
        "\n",
        "def resize(image, height, width):\n",
        "    \"\"\"\n",
        "    Alters image size by either copying or deleting rows and columns of pixels as necassary\n",
        "    \"\"\"\n",
        "    #Convert to grayscale if necessary\n",
        "    if len(image.shape)>2:\n",
        "        image_new = np.zeros((height,width, image.shape[2]))\n",
        "        for i in range(image.shape[2]):\n",
        "            image_new[:,:,i] = transform_height(transform_width(image[:,:,i], width), height)\n",
        "    else: \n",
        "        image_new=transform_height(transform_width(image, width), height)\n",
        "    return image_new/np.max([np.max(image_new), 1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}